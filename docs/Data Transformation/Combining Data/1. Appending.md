Es la concatenación de dos o más conjuntos de datos, útil en los casos que se tiene una misma estructura divida en varios archivos, como por ejemplo archivos excels de las ventas de cada año en archivos diferentes. Las condiciones que se debe tener en cuenta para una correcta concatenación son las siguientes:

* Los nombres de las columnas deben ser las mismas en todos los archivos, así no se genera columnas con valores nulos.
* Las columnas deben estar en el mismo orden en todos los archivos.
* El tipo de dato de los archivos deben ser los mismos o ser compatibles (ej. int - float)

## Sintáxis

=== "Pandas"

    ```py
    DataFrame.concat([df1, df2, ...]) #(1)!
    ```
    
    1. Permite concatenar **varios dataframes**.

=== "Polars"

    ```py
    DataFrame.vstack() #(1)!
    
    DataFrame.concat([df1, df2, ...], *, how='vertical') #(2)!
    ```
    
    1. Permite concatenar solo **dos dataframes**, está optimizado solo para este caso.
    2. Perimte concatenar **varios dataframes**, siendo de forma vertical la única opción.

=== "SQL Server"

    ```sql
    SELECT col1, col2, ..., coln FROM tabla_1
    UNION | UNION ALL --(1)!
    SELECT col1, col2, ..., coln FROM tabla_2
    UNION | UNION ALL
    SELECT col1, col2, ..., coln FROM tabla_3
    ```
    
    1. `UNION` es para concatenar **sin valores duplicados**, mientras que `UNION ALL` **sí acepta los valores duplicados**.

!!! success "Significado del `*` en los parámetros"
    El significado que se usa en estos casos es que los parámetros que están antes del asterisco deben proporcionarse como argumentos posicionales (es decir, por su posición no es obligatorio usar su nombre). Todos los parámetros que aparecen después del `*` deben proporcionarse como argumentos de palabra clave (es decir, especificando su nombre, no importa el orden).

## Ejemplos

Los datos para este ejemplo estan [aquí](https://github.com/darylcs2325/mkdocs-courses).

!!! example "Unir todos los archivos de ventas desde el año 1996 al 1998."

    === "Pandas"

        ```py
        pd_sales_1996 = pd.read_csv("./Dataset/Sales_1996.csv", encoding='latin-1') #(1)!
        pd_sales_1997 = pd.read_csv("./Dataset/Sales_1997.csv", encoding='latin-1')
        pd_sales_1998 = pd.read_csv("./Dataset/Sales_1998.csv", encoding='latin-1')

        """ Se verifca que las columnas tengan el mismo nombre en sus headers, podrá notar que `pd_sales_1998`
        difere con las otras en la columna `Company Name`, debería ser `CompanyName`."""

        pd_sales_1998 = pd_sales_1998.rename(columns={'Company Name': 'CompanyName'}) #(2)!

        pd_sales=pd.concat([pd_sales_1996, pd_sales_1997, pd_sales_1998])
        print(pd_sales.head())
        ```

        1. Por lo general, el `enconding` que se utiliza es el `utf-8`, que viene por defecto, pero en este caso hay caracteres que no cumplen con este, por tal motivo se utiliza `latin-1`.
        2. `#!py rename(columns={'Nombre actual': 'Nombre nuevo'})`, permite cambiar el `#!py 'Nombre actual'` por `#!py 'Nombre nuevo'`

        |EmployeeID |  RegionDescription |CompanyName       | Year | Month     |Total Quantity |  Total Sales|
        |:---------:|:------------------:|:----------------:|:----:|:---------:|:-------------:|:-----------:|
        |  7        |  Western ...       |Ana Trujillo ...  | 1996 | September |  6            |  88.8       |
        |  3        |  Southern ...      |Antonio Moreno ...| 1996 | November  |  24           |  403.2      |
        |  8        |  Northern ...      |Around the Horn   | 1996 | December  |  55           |  899.0      |
        |  6        |  Western ...       |Around the Horn   | 1996 | November  |  50           |  480.0      |
        |  7        |  Western ...       |B's Beverages     | 1996 | August    |  39           |  479.4      |


    === "Polars"

        ```py
        pl_sales_1996 = pl.read_csv("./Dataset/Sales_1996.csv", encoding='latin-1')
        pl_sales_1997 = pl.read_csv("./Dataset/Sales_1997.csv", encoding='latin-1')
        pl_sales_1998 = pl.read_csv("./Dataset/Sales_1998.csv", encoding='latin-1')

        # De igual forma, cambiamos el nombre de `pl_sales_1998`.

        pl_sales_1998 = pl_sales_1998.rename({'Company Name': 'CompanyName'}) #(1)!

        pl_sales = pl.concat([pl_sales_1996, pl_sales_1997, pl_sales_1998]) #(2)!

        print(pl_sales)
        ```

        1. Es lo mismo que en Pandas, pero no es necesario indicar el nombre del arámetro con `#!py columns=`.
        2. No es necesario indicar el `#!py how="vertical"`

        |EmployeeID |  RegionDescription |CompanyName       | Year | Month     |Total Quantity |  Total Sales|
        |:---------:|:------------------:|:----------------:|:----:|:---------:|:-------------:|:-----------:|
        |   *i64*   |        *str*       |      *str*       | *i64*|  *str*    |    *i64*      |     *f64*   |
        |  7        |  Western ...       |Ana Trujillo ...  | 1996 | September |  6            |  88.8       |
        |  3        |  Southern ...      |Antonio Moreno ...| 1996 | November  |  24           |  403.2      |
        |  8        |  Northern ...      |Around the Horn   | 1996 | December  |  55           |  899.0      |
        |  6        |  Western ...       |Around the Horn   | 1996 | November  |  50           |  480.0      |
        |  7        |  Western ...       |B's Beverages     | 1996 | August    |  39           |  479.4      |
        
    === "SQL Server"

        ```sql hl_lines="1-7"
        WITH Sales_Total AS (
            SELECT EmployeeID, RegionDescription, CompanyName, Year, Month, Total_Quantity, Total_Sales FROM Sales_1996
            UNION
            SELECT * FROM Sales_1997
            UNION
            SELECT * FROM Sales_1998
        ) --(1)!

        SELECT * FROM Sales_Total;
        ```

        1. Se crea un **CTE** para guardar los datos de la nueva tabla que es la concatenación de los archivos.

        |EmployeeID |  RegionDescription |CompanyName       | Year | Month     | Total_Quantity| Total_Sales |
        |:---------:|:------------------:|:----------------:|:----:|:---------:|:-------------:|:-----------:|
        |  7        |  Western ...       |Ana Trujillo ...  | 1996 | September |  6            |  88.8       |
        |  3        |  Southern ...      |Antonio Moreno ...| 1996 | November  |  24           |  403.2      |
        |  8        |  Northern ...      |Around the Horn   | 1996 | December  |  55           |  899.0      |
        |  6        |  Western ...       |Around the Horn   | 1996 | November  |  50           |  480.0      |
        |  7        |  Western ...       |B's Beverages     | 1996 | August    |  39           |  479.4      |

!!! tip "Manejo de chunks"
    Una de las cualidades de `pl.vstack` (por ende, también para `pl.concat` ya que este usar `vstack` de base) es que evita generar copias de los datos de `df2` a los **chunks** de `df1`.

    Polars almacena los datos internamente en **chunks** (bloques de memoria) y `pl.vstack` simplemente agrega los **chunks** de `df2` a `df1`, pero si nosotros hacemos varias operaciones de `vstack`, es posible que el DataFrame original tenga muchos chunks pequeños, esto afectaría negativamente al rendimiento de operaciones futuras a ese DataFrame. En tales casos, se recomienda llamar a `DataFrame.rechunk()` al final para consolidar los datos en un solo **chunk** contiguo, mejorando así el rendimiento.